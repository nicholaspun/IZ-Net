{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceDetection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnRCl9X3xQmr"
      },
      "source": [
        "import io\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image, ImageDraw\n",
        "from keras import Sequential, Model\n",
        "from keras import backend as K\n",
        "from keras.layers import Conv2D, Dense, Flatten, Reshape, Input, BatchNormalization, MaxPooling2D, LeakyReLU, Add\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "BASE_PATH = os.path.join('.', 'drive', 'My Drive', 'IZ*Net')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnBeLpuOcFFk"
      },
      "source": [
        "ANCHOR_SIZES = np.array([[1, 1], [1, 1.15]])\n",
        "\n",
        "def getHelperFunctions(gridSize):\n",
        "  def getXOffsets(theGridSize): return lambda: K.expand_dims(K.arange(theGridSize, dtype=tf.float64))\n",
        "  def getYOffsets(theGridSize): return lambda: K.expand_dims(K.reshape(K.arange(theGridSize, dtype=tf.float64), (theGridSize, 1)))\n",
        "  return (getXOffsets(gridSize), getYOffsets(gridSize))\n",
        "\n",
        "def yoloLoss(yTrueIn, yPredIn):\n",
        "  LAMBDA_COORD = 25\n",
        "  LAMBDA_NOOBJ = 0.5\n",
        "  (BATCH_SIZE, N_ROWS, _, _, _) = yTrueIn.shape \n",
        "\n",
        "  yTrue = K.cast(yTrueIn, 'float64')\n",
        "  yPred = K.cast(yPredIn, 'float64')\n",
        "\n",
        "  (getXOffsets, getYOffsets) = getHelperFunctions(N_ROWS)\n",
        "\n",
        "  yTrueXRealCoords = K.expand_dims(yTrue[...,1] + getXOffsets())\n",
        "  yTrueYRealCoords = K.expand_dims(yTrue[...,2] + getYOffsets())\n",
        "  yTrueWithRealCoords = K.concatenate([K.expand_dims(yTrue[...,0]), yTrueXRealCoords, yTrueYRealCoords, K.expand_dims(yTrue[...,3]), K.expand_dims(yTrue[...,4])])\n",
        "\n",
        "  yPredCRealCoords = K.expand_dims(tf.sigmoid(yPred[...,0]))\n",
        "  yPredXRealCoords = K.expand_dims(tf.sigmoid(yPred[...,1]) + getXOffsets())\n",
        "  yPredYRealCoords = K.expand_dims(tf.sigmoid(yPred[...,2]) + getYOffsets())\n",
        "  yPredWRealCoords = K.expand_dims(K.exp(yPred[...,3]) * ANCHOR_SIZES[...,0])\n",
        "  yPredHRealCoords = K.expand_dims(K.exp(yPred[...,4]) * ANCHOR_SIZES[...,1])\n",
        "  yPredWithRealCoords = K.concatenate([yPredCRealCoords, yPredXRealCoords, yPredYRealCoords, yPredWRealCoords, yPredHRealCoords])\n",
        "\n",
        "  indicatorMask = K.expand_dims(yTrueWithRealCoords[...,0])\n",
        "  xyLoss = K.sum(K.square((yTrueWithRealCoords[...,1:3] - yPredWithRealCoords[...,1:3]) * indicatorMask))\n",
        "  whLoss = K.sum(K.square((K.sqrt(yTrueWithRealCoords[...,3:5]) - K.sqrt(yPredWithRealCoords[...,3:5])) * indicatorMask))\n",
        "\n",
        "  topLeftCoordOfIntersect = K.maximum(yPredWithRealCoords[...,1:3] - (yPredWithRealCoords[...,3:5] / 2.), yTrueWithRealCoords[...,1:3] - (yTrueWithRealCoords[...,3:5] / 2.))\n",
        "  bottomRightCoordOfIntersect = K.minimum(yPredWithRealCoords[...,1:3] + (yPredWithRealCoords[...,3:5] / 2.), yTrueWithRealCoords[...,1:3] + (yTrueWithRealCoords[...,3:5] / 2.))\n",
        "  widthAndHeightOfIntersect = K.maximum(bottomRightCoordOfIntersect - topLeftCoordOfIntersect, 0)\n",
        "  intersectionAreas = widthAndHeightOfIntersect[...,0] * widthAndHeightOfIntersect[...,1]\n",
        "  encodingAreas = yPredWithRealCoords[...,3] * yPredWithRealCoords[...,4]\n",
        "  boundingBoxAreas = yTrueWithRealCoords[...,3] * yTrueWithRealCoords[...,4]\n",
        "  unionAreas = encodingAreas + boundingBoxAreas - intersectionAreas\n",
        "  IOUScores = tf.truediv(intersectionAreas, unionAreas)\n",
        "\n",
        "  noObjCLoss = LAMBDA_NOOBJ * (K.sum(K.square(K.expand_dims(yPredWithRealCoords[...,0]) * (1. - indicatorMask))) + K.sum(K.square(K.expand_dims(1 - yPredWithRealCoords[...,0]) * indicatorMask)))\n",
        "  objCLoss = K.sum(K.square(K.expand_dims(yTrueWithRealCoords[...,0] - IOUScores) * indicatorMask))\n",
        "\n",
        "  return tf.truediv(noObjCLoss + objCLoss + LAMBDA_COORD * (xyLoss + whLoss), BATCH_SIZE)\n",
        "\n",
        "def yoloAccuracy(yTrueIn, yPredIn):\n",
        "  (_, N_ROWS, _, _, _) = yTrueIn.shape \n",
        "\n",
        "  yTrue = K.cast(yTrueIn, 'float64')\n",
        "  yPred = K.cast(yPredIn, 'float64')\n",
        "\n",
        "  (getXOffsets, getYOffsets) = getHelperFunctions(N_ROWS)\n",
        "\n",
        "  yTrueXRealCoords = K.expand_dims(yTrue[...,1] + getXOffsets())\n",
        "  yTrueYRealCoords = K.expand_dims(yTrue[...,2] + getYOffsets())\n",
        "  yTrueWithRealCoords = K.concatenate([K.expand_dims(yTrue[...,0]), yTrueXRealCoords, yTrueYRealCoords, K.expand_dims(yTrue[...,3]), K.expand_dims(yTrue[...,4])])\n",
        "\n",
        "  yPredCRealCoords = K.expand_dims(tf.sigmoid(yPred[...,0]))\n",
        "  yPredXRealCoords = K.expand_dims(tf.sigmoid(yPred[...,1]) + getXOffsets())\n",
        "  yPredYRealCoords = K.expand_dims(tf.sigmoid(yPred[...,2]) + getYOffsets())\n",
        "  yPredWRealCoords = K.expand_dims(K.exp(yPred[...,3]) * ANCHOR_SIZES[...,0])\n",
        "  yPredHRealCoords = K.expand_dims(K.exp(yPred[...,4]) * ANCHOR_SIZES[...,1])\n",
        "  yPredWithRealCoords = K.concatenate([yPredCRealCoords, yPredXRealCoords, yPredYRealCoords, yPredWRealCoords, yPredHRealCoords])\n",
        "\n",
        "  topLeftCoordOfIntersect = K.maximum(yPredWithRealCoords[...,1:3] - (yPredWithRealCoords[...,3:5] / 2.), yTrueWithRealCoords[...,1:3] - (yTrueWithRealCoords[...,3:5] / 2.))\n",
        "  bottomRightCoordOfIntersect = K.minimum(yPredWithRealCoords[...,1:3] + (yPredWithRealCoords[...,3:5] / 2.), yTrueWithRealCoords[...,1:3] + (yTrueWithRealCoords[...,3:5] / 2.))\n",
        "  widthAndHeightOfIntersect = K.maximum(bottomRightCoordOfIntersect - topLeftCoordOfIntersect, 0)\n",
        "  intersectionAreas = widthAndHeightOfIntersect[...,0] * widthAndHeightOfIntersect[...,1]\n",
        "  encodingAreas = yPredWithRealCoords[...,3] * yPredWithRealCoords[...,4]\n",
        "  boundingBoxAreas = yTrueWithRealCoords[...,3] * yTrueWithRealCoords[...,4]\n",
        "  unionAreas = encodingAreas + boundingBoxAreas - intersectionAreas\n",
        "  IOUScores = tf.truediv(intersectionAreas, unionAreas)\n",
        "\n",
        "  return tf.truediv(K.sum(IOUScores * yPredWithRealCoords[...,0] * yTrueWithRealCoords[...,0]), K.sum(yTrueWithRealCoords[...,0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSdRrnxok_30"
      },
      "source": [
        "def Conv(XInput, filters, kernel_size, strides):\n",
        "  X = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(XInput)\n",
        "  X = BatchNormalization()(X)\n",
        "  X = LeakyReLU(0.1)(X)\n",
        "  return X\n",
        "\n",
        "def Residual(XInput, filters):\n",
        "  XBranch = Conv(XInput, filters=filters, kernel_size=1, strides=1)\n",
        "  XBranch = Conv(XBranch, filters=filters * 2, kernel_size=3, strides=1)\n",
        "  X = Add()([XInput, XBranch])\n",
        "  return X\n",
        "\n",
        "def network():\n",
        "  X_input = Input((416, 416, 3))\n",
        "\n",
        "  X = Conv(X_input, filters=32, kernel_size=3, strides=1)\n",
        "  X = Conv(X, filters=64, kernel_size=3, strides=2)\n",
        "  X = Residual(X, filters=32)\n",
        "  X = Conv(X, filters=128, kernel_size=3, strides=2)\n",
        "  X = Residual(X, filters=64)\n",
        "  X = Residual(X, filters=64)\n",
        "  X = Conv(X, filters=256, kernel_size=3, strides=2)\n",
        "  X = Residual(X, filters=128)\n",
        "  X = Residual(X, filters=128)\n",
        "  X = Residual(X, filters=128)\n",
        "  X = Residual(X, filters=128)\n",
        "  X = Residual(X, filters=128)\n",
        "  X = Residual(X, filters=128)\n",
        "  X = Residual(X, filters=128)\n",
        "  X = Residual(X, filters=128)\n",
        "  X = Conv(X, filters=512, kernel_size=3, strides=2)\n",
        "  X = Residual(X, filters=256)\n",
        "  X = Residual(X, filters=256)\n",
        "  X = Residual(X, filters=256)\n",
        "  X = Residual(X, filters=256)\n",
        "  X = Residual(X, filters=256)\n",
        "  X = Residual(X, filters=256)\n",
        "  X = Residual(X, filters=256)\n",
        "  X = Residual(X, filters=256)\n",
        "  X = Conv(X, filters=1024, kernel_size=3, strides=2)\n",
        "  X = Residual(X, filters=512)\n",
        "  X = Residual(X, filters=512)\n",
        "  X = Residual(X, filters=512)\n",
        "  X = Residual(X, filters=512)\n",
        "  X = Conv2D(128, 1)(X)\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(1690)(X)\n",
        "  X = Reshape((13, 13, 2, 5))(X)\n",
        "\n",
        "  return Model(inputs=X_input, outputs=X)\n",
        "\n",
        "# print(network().summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpMvXItfcJCN"
      },
      "source": [
        "def load_img(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (416, 416))\n",
        "    img = img[..., ::-1]  # Reverse channels\n",
        "    img = np.around(img/255.0, decimals=12)  # Normalize\n",
        "    return img\n",
        "\n",
        "def getBoundingBoxCoordinates(image, boundingBoxRow, boundingBoxCol, anchorBox, boundingBoxInfo):\n",
        "    imageWidth, imageHeight = image.size\n",
        "    widthScale = imageWidth / 13\n",
        "    heightScale = imageHeight / 13\n",
        "\n",
        "    (bbInfoX, bbInfoY) = tf.sigmoid(boundingBoxInfo[:2])\n",
        "    (bbInfoW, bbInfoH) = tf.exp(boundingBoxInfo[2:]) * ANCHOR_SIZES[anchorBox]\n",
        "    \n",
        "    midX = bbInfoX + boundingBoxCol\n",
        "    midY = bbInfoY + boundingBoxRow\n",
        "\n",
        "    startX = (midX - (bbInfoW / 2.)) * widthScale\n",
        "    startY = (midY - (bbInfoH / 2.)) * heightScale\n",
        "    endX = (midX + (bbInfoW / 2.)) * widthScale\n",
        "    endY = (midY + (bbInfoH / 2.)) * heightScale\n",
        "\n",
        "    return [startY, startX, endY, endX]\n",
        "\n",
        "def drawBoxes(image, boxes):\n",
        "    Draw = ImageDraw.Draw(image)\n",
        "\n",
        "    for box in boxes:\n",
        "      [startY, startX, endY, endX] = box\n",
        "      for i in range(2):\n",
        "        Draw.rectangle([(startX + i, startY + i), (endX - i, endY - i)], outline='red')\n",
        "\n",
        "def drawImage(imgPath, encoding):\n",
        "    theImage = Image.open(imgPath).convert('RGB').resize((299, 299))\n",
        "\n",
        "    boundingBoxes = []\n",
        "    confidenceScores = []\n",
        "    for row in range(13):\n",
        "        for col in range(13):\n",
        "          for boxNum in range(2):\n",
        "            boundingBoxes.append(getBoundingBoxCoordinates(theImage, row, col, boxNum, encoding[row][col][boxNum][1:]))\n",
        "            confidenceScores.append(tf.sigmoid(encoding[row][col][boxNum][0]))\n",
        "\n",
        "    selectedIndices = tf.image.non_max_suppression(boundingBoxes, confidenceScores, max_output_size=12, iou_threshold=0.5)\n",
        "    selectedBoxes = tf.gather(boundingBoxes, selectedIndices)\n",
        "    selectedBoxesConfidences = tf.gather(confidenceScores, selectedIndices)\n",
        "    \n",
        "    highConfidenceBoxes = [box for (box, boxConfidence) in zip(selectedBoxes, selectedBoxesConfidences) if boxConfidence > 0.3]\n",
        "    drawBoxes(theImage, highConfidenceBoxes)\n",
        "    # print(\"Confidence Scores: \", tf.gather(confidenceScores, selectedIndices))\n",
        "    cv2_imshow(np.array(theImage)[...,::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQvFcy0sUsRh"
      },
      "source": [
        "data = {}\n",
        "\n",
        "with open(os.path.join(BASE_PATH, 'output.json')) as infile:\n",
        "    memfile = io.BytesIO()\n",
        "    memfile.write(json.load(infile).encode('latin-1'))\n",
        "    memfile.seek(0)\n",
        "    data = np.load(memfile, allow_pickle=True)[()] # See https://stackoverflow.com/questions/30811918/saving-dictionary-of-numpy-arrays/45661259\n",
        "\n",
        "dataKeysList = list(data.keys())\n",
        "\n",
        "model = network()\n",
        "model.load_weights(os.path.join(BASE_PATH, 'network4_yolo_highestMeanAccuracy.h5'))\n",
        "model.compile(loss=yoloLoss, optimizer=SGD(learning_rate=1e-4, momentum=0.92, clipnorm=1), metrics=[yoloAccuracy])\n",
        "\n",
        "ACCURACY_SAVE_PATH = os.path.join(BASE_PATH, 'network4_yolo_highestMeanAccuracy.h5')\n",
        "START_EPOCH = 0\n",
        "NUM_EPOCH = 30\n",
        "BATCH_SIZE = 32\n",
        "losses = []\n",
        "accuracies = []\n",
        "maxMeanAccuracySofar = 0\n",
        "for epochNum in range(START_EPOCH + 1, START_EPOCH + NUM_EPOCH + 1):\n",
        "  print(\"Begin epoch {}/{}\".format(epochNum, START_EPOCH + NUM_EPOCH))\n",
        "  random.shuffle(dataKeysList)\n",
        "  batches = [dataKeysList[i:i + BATCH_SIZE] for i in range(0, len(dataKeysList), BATCH_SIZE)]\n",
        "\n",
        "  batchAccuracies = []\n",
        "  for batchNum, theBatch in enumerate(batches, start=1):\n",
        "    print(\"Training on batch {}/{} ........\".format(batchNum, len(batches)), end=\" \")\n",
        "    inputImgs = np.array([load_img(os.path.join(BASE_PATH, path)) for path in theBatch])\n",
        "    outputEncoding = np.array([data[path] for path in theBatch])\n",
        "    (loss, accuracy) = model.train_on_batch(x=inputImgs, y=outputEncoding)\n",
        "    print(\"Loss: {}, Accuracy: {}\".format(loss, accuracy))\n",
        "    losses.append(loss)\n",
        "    batchAccuracies.append(accuracy)\n",
        "\n",
        "  accuracies += batchAccuracies\n",
        "  meanAccuracy = np.mean(np.array(batchAccuracies))\n",
        "  if meanAccuracy > maxMeanAccuracySofar:\n",
        "    maxMeanAccuracySofar = meanAccuracy\n",
        "    model.save(ACCURACY_SAVE_PATH)\n",
        "  \n",
        "  if epochNum % 10 == 0:\n",
        "    model.save(os.path.join(BASE_PATH, 'network4_yolo_epoch_{}.h5'.format(epochNum)))\n",
        "\n",
        "plt.plot(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw6-_O44NMda"
      },
      "source": [
        "# Local paths to images\n",
        "allImages = [(member, imageName) for member in os.listdir(os.path.join(BASE_PATH, 'train')) for imageName in os.listdir(os.path.join(BASE_PATH, 'train', member))]\n",
        "random.shuffle(allImages)\n",
        "\n",
        "model = network()\n",
        "model.load_weights(os.path.join(BASE_PATH, 'network4_yolo_highestMeanAccuracy.h5')) # Local path again\n",
        "\n",
        "for (member, imageName) in allImages[:10]:\n",
        "  print(member, imageName)\n",
        "  fullPath = os.path.join(BASE_PATH, 'train', member, imageName)\n",
        "  drawImage(fullPath, tf.reshape(model(np.array([load_img(fullPath)])), (13, 13, 2, 5)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}